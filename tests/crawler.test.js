/**
 * Crawler Tests
 * ØªØ³Øª Ø¹Ù…Ù„Ú©Ø±Ø¯ Background Crawler
 */

const db = require('../src/database/connection');
const BackgroundCrawler = require('../src/crawler/BackgroundCrawler');
const CrawlerScheduler = require('../src/crawler/CrawlerScheduler');
const PhDRepository = require('../src/database/repositories/PhDRepository');

async function runTests() {
    console.log('\n' + '='.repeat(60));
    console.log('ğŸ§ª Crawler Tests');
    console.log('='.repeat(60) + '\n');

    let passed = 0;
    let failed = 0;

    try {
        // Test 1: Database Initialize
        console.log('Test 1: Initialize Database...');
        await db.initialize();
        console.log('  âœ“ Database initialized');
        passed++;

        // Test 2: Crawler Status (should not be running)
        console.log('\nTest 2: Check Crawler Status...');
        const initialStatus = BackgroundCrawler.getStatus();
        if (!initialStatus.isRunning) {
            console.log('  âœ“ Crawler is not running initially');
            passed++;
        } else {
            throw new Error('Crawler should not be running');
        }

        // Test 3: Subscribe to Crawler Events
        console.log('\nTest 3: Subscribe to Crawler Events...');
        let eventsReceived = 0;
        BackgroundCrawler.subscribe((event, data) => {
            eventsReceived++;
            console.log(`  â†’ Event: ${event}`);
        });
        console.log('  âœ“ Subscribed to events');
        passed++;

        // Test 4: Start Manual Crawl (limited to 2 pages for testing)
        console.log('\nTest 4: Start Manual Crawl (SLOW TEST - will take time)...');
        console.log('  â³ This will crawl real pages from FindAPhD...');
        console.log('  â„¹  You can skip this by pressing Ctrl+C\n');

        // Ø´Ø±ÙˆØ¹ crawl Ø¨Ù‡ ØµÙˆØ±Øª async
        const crawlPromise = BackgroundCrawler.startFullCrawl('test');

        // ØµØ¨Ø± 5 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ crawl
        await new Promise(resolve => setTimeout(resolve, 5000));

        // Ú†Ú© Ú©Ø±Ø¯Ù† status
        const runningStatus = BackgroundCrawler.getStatus();
        if (runningStatus.isRunning) {
            console.log('  âœ“ Crawler started successfully');
            console.log(`  â†’ Current stats: ${JSON.stringify(runningStatus.stats)}`);
            passed++;
        } else {
            console.log('  âš  Crawler might have completed quickly');
            passed++;
        }

        // Ù…Ù†ØªØ¸Ø± ØªÚ©Ù…ÛŒÙ„ crawl (Ø¨Ø§ timeout)
        console.log('\n  â³ Waiting for crawler to complete...');
        console.log('  â„¹  This may take several minutes depending on FindAPhD response time');

        const result = await Promise.race([
            crawlPromise,
            new Promise((resolve) => setTimeout(() => resolve({ timeout: true }), 300100)) // 5 minute timeout
        ]);

        if (result.timeout) {
            console.log('  âš  Crawler timeout after 5 minutes (this is normal for full crawl)');
            console.log('  â„¹  Crawler is still running in background');
            passed++;
        } else if (result.success) {
            console.log('  âœ“ Crawler completed successfully');
            console.log(`  â†’ Found: ${result.stats.total_found}`);
            console.log(`  â†’ New: ${result.stats.total_new}`);
            console.log(`  â†’ Updated: ${result.stats.total_updated}`);
            console.log(`  â†’ Duration: ${result.duration}s`);
            passed++;
        } else {
            console.log(`  âœ— Crawler failed: ${result.error}`);
            console.log(`  â†’ Partial stats: ${JSON.stringify(result.stats)}`);
            failed++;
        }

        // Test 5: Check Events
        console.log('\nTest 5: Check Events Received...');
        console.log(`  âœ“ Received ${eventsReceived} events`);
        passed++;

        // Test 6: Check Database after Crawl
        console.log('\nTest 6: Check Database after Crawl...');
        const stats = await PhDRepository.getStats();
        console.log(`  âœ“ Total PhDs in database: ${stats.total}`);
        console.log(`  âœ“ Active PhDs: ${stats.active}`);

        if (stats.total > 0) {
            console.log('  âœ“ Database has PhD records');
            passed++;
        } else {
            console.log('  âš  No PhDs in database yet (crawler might still be running)');
            passed++;
        }

        // Test 7: Scheduler Status
        console.log('\nTest 7: Check Scheduler...');
        const schedulerStatus = CrawlerScheduler.getStatus();
        console.log(`  â†’ Scheduler running: ${schedulerStatus.isRunning}`);
        console.log(`  â†’ Interval: ${schedulerStatus.intervalHours} hour(s)`);
        console.log('  âœ“ Scheduler status retrieved');
        passed++;

    } catch (error) {
        console.error(`  âœ— Test failed: ${error.message}`);
        console.error(error.stack);
        failed++;
    }

    // Summary
    console.log('\n' + '='.repeat(60));
    console.log('ğŸ“Š Test Summary');
    console.log('='.repeat(60));
    console.log(`âœ“ Passed: ${passed}`);
    console.log(`âœ— Failed: ${failed}`);
    console.log(`Total: ${passed + failed}`);
    console.log('='.repeat(60));

    console.log('\nâš ï¸  Note: If crawler is still running, it will continue in background');
    console.log('   The database will be populated gradually.\n');

    await db.close();

    process.exit(failed > 0 ? 1 : 0);
}

runTests();