# FindAPhD Search API v2.0 ğŸ“

> **Ø¯Ø³ØªØ±Ø³ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ù‡ 3001+ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø¯Ú©ØªØ±Ø§ Ø§Ø² FindAPhD.com Ø§Ø² Ø·Ø±ÛŒÙ‚ REST API Ø¨Ø§ Ù…Ø¹Ù…Ø§Ø±ÛŒ Background Crawler**

[![Node.js](https://img.shields.io/badge/Node.js-16+-green.svg)](https://nodejs.org/)
[![Express](https://img.shields.io/badge/Express-5.1.0-blue.svg)](https://expressjs.com/)
[![Database](https://img.shields.io/badge/Database-SQLite%2FPostgreSQL-orange.svg)](https://www.sqlite.org/)
[![Swagger](https://img.shields.io/badge/API-Swagger-brightgreen.svg)](http://localhost:3001/api-docs)

## ğŸ†• ØªØºÛŒÛŒØ±Ø§Øª Ø§Ø³Ø§Ø³ÛŒ Ø¯Ø± Ù†Ø³Ø®Ù‡ 2.0

### Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù‚Ø¨Ù„ÛŒ (v1.0) âŒ
```
User Request â†’ API â†’ Playwright Crawler â†’ FindAPhD.com â†’ Return Results
â±ï¸  Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®: 10-15 Ø«Ø§Ù†ÛŒÙ‡
ğŸ”¥ ÙØ´Ø§Ø± Ø²ÛŒØ§Ø¯ Ø±ÙˆÛŒ FindAPhD Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª
```

### Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø¬Ø¯ÛŒØ¯ (v2.0) âœ…
```
Background Crawler (Ù‡Ø± 1 Ø³Ø§Ø¹Øª) â†’ Database â†’ API â†’ User (< 50ms)
âš¡ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®: Ú©Ù…ØªØ± Ø§Ø² 50 Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡
ğŸ¯ ÙØ´Ø§Ø± Ú©Ù… Ø±ÙˆÛŒ FindAPhD (ÙÙ‚Ø· Ù‡Ø± 1 Ø³Ø§Ø¹Øª)
ğŸ“Š 3001+ PhD position Ù‡Ù…ÛŒØ´Ù‡ Ø¯Ø± Ø¯Ø³ØªØ±Ø³
```

---

## ğŸš€ Quick Start

```bash
# 1. Ù†ØµØ¨ dependencies
npm install

# 2. Ù†ØµØ¨ Playwright browsers
npx playwright install chromium

# 3. Ø§Ø¬Ø±Ø§ÛŒ Ø³Ø±ÙˆØ±
npm start

# 4. Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Swagger UI
http://localhost:3001/api-docs
```

**Ø³Ø±ÙˆØ± Ø´Ù…Ø§ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³Øª! ğŸ‰**
- Database Ø®ÙˆØ¯Ú©Ø§Ø± initialize Ù…ÛŒâ€ŒØ´ÙˆØ¯
- Crawler Ø¨Ù‡ ØµÙˆØ±Øª background Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯
- API Ø¢Ù…Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§Ø³Øª

---

## âœ¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø³Ø®Ù‡ 2.0

### ğŸ”¥ Ø¬Ø¯ÛŒØ¯ Ø¯Ø± v2.0
- âœ… **Background Crawler**: Ú©Ù„ FindAPhD Ø±Ùˆ Ù‡Ø± 1 Ø³Ø§Ø¹Øª crawl Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- âœ… **Database Layer**: SQLite/PostgreSQL Ø¨Ø§ Repository Pattern
- âœ… **Ø³Ø±Ø¹Øª Ø¨Ø§Ù„Ø§**: API response < 50ms (Ø¨Ù‡ Ø¬Ø§ÛŒ 10-15s)
- âœ… **Offline Support**: Ø§Ú¯Ù‡ FindAPhD down Ø¨ÙˆØ¯ØŒ API Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù‡
- âœ… **Monitoring**: Dashboard Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ crawler status
- âœ… **Scheduler**: Ø§Ø¬Ø±Ø§ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø± Ù‡Ø± 1 Ø³Ø§Ø¹Øª
- âœ… **Observer Pattern**: Real-time monitoring crawler events

### ğŸ¯ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒ
- âœ… **REST API**: 15+ endpoint Ø¨Ø±Ø§ÛŒ searchØŒ statsØŒ crawler admin
- âœ… **Pagination**: ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ Ø³Ø±ÛŒØ¹ Ø¨Ø§ limit/offset
- âœ… **Advanced Filters**: Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ disciplineØŒ countryØŒ fundingØŒ university
- âœ… **Swagger UI**: Ù…Ø³ØªÙ†Ø¯Ø§Øª ØªØ¹Ø§Ù…Ù„ÛŒ Ú©Ø§Ù…Ù„
- âœ… **SOLID Principles**: Ù…Ø¹Ù…Ø§Ø±ÛŒ ØªÙ…ÛŒØ² Ùˆ Ù‚Ø§Ø¨Ù„ ØªÙˆØ³Ø¹Ù‡
- âœ… **Design Patterns**: SingletonØŒ RepositoryØŒ ObserverØŒ Strategy

---

## ğŸ“¡ API Endpoints

### PhD Search (5 endpoints)
```bash
GET  /api/phd/search              # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ùˆ pagination
POST /api/phd/search              # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ body (ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡)
GET  /api/phd/:id                 # Ø¬Ø²Ø¦ÛŒØ§Øª ÛŒÚ© PhD
GET  /api/phd/stats/summary       # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
GET  /api/phd/filters/available   # Ù„ÛŒØ³Øª ÙÛŒÙ„ØªØ±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
```

### Crawler Admin (8 endpoints)
```bash
GET  /api/crawler/status          # ÙˆØ¶Ø¹ÛŒØª ÙØ¹Ù„ÛŒ crawler
POST /api/crawler/trigger         # Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒ crawler
GET  /api/crawler/logs            # ØªØ§Ø±ÛŒØ®Ú†Ù‡ crawler runs
GET  /api/crawler/logs/:id        # Ø¬Ø²Ø¦ÛŒØ§Øª ÛŒÚ© crawler run
GET  /api/crawler/stats           # Ø¢Ù…Ø§Ø± crawler
GET  /api/crawler/events          # Real-time events
PUT  /api/crawler/settings/interval    # ØªÙ†Ø¸ÛŒÙ… Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ
PUT  /api/crawler/settings/toggle      # ÙØ¹Ø§Ù„/ØºÛŒØ±ÙØ¹Ø§Ù„
```

### Health (2 endpoints)
```bash
GET /api/health                   # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³
GET /api/health/ready             # Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø±Ø®ÙˆØ§Ø³Øª
```

**Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¯Ø± Swagger**: http://localhost:3001/api-docs

---

## ğŸ’» Ù†Ø­ÙˆÙ‡ Ø§Ø³ØªÙØ§Ø¯Ù‡

### 1ï¸âƒ£ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø§Ø¯Ù‡
```bash
curl "http://localhost:3001/api/phd/search?keywords=machine+learning&page=1&limit=20"
```

### 2ï¸âƒ£ Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø§ ÙÛŒÙ„ØªØ±
```bash
curl "http://localhost:3001/api/phd/search?keywords=AI&country=United+Kingdom&funding_type=Funded+PhD+Project"
```

### 3ï¸âƒ£ Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø±
```bash
curl "http://localhost:3001/api/phd/stats/summary"
```

### 4ï¸âƒ£ ÙˆØ¶Ø¹ÛŒØª Crawler
```bash
curl "http://localhost:3001/api/crawler/status"
```

### 5ï¸âƒ£ Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÛŒ Crawler
```bash
curl -X POST "http://localhost:3001/api/crawler/trigger"
```

---

## ğŸ“Š Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Background Crawler (Every 1 Hour)        â”‚
â”‚  â€¢ Crawls ALL PhD positions (3001+)             â”‚
â”‚  â€¢ Updates existing records                     â”‚
â”‚  â€¢ Marks deleted positions                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚    Database     â”‚
          â”‚  (SQLite/PG)    â”‚
          â”‚  â€¢ phd_positionsâ”‚
          â”‚  â€¢ crawler_logs â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   REST API      â”‚
          â”‚  â€¢ Search       â”‚
          â”‚  â€¢ Filters      â”‚
          â”‚  â€¢ Pagination   â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
              User Response (< 50ms)
```

### Ø¬Ø±ÛŒØ§Ù† Ú©Ø§Ù…Ù„:
1. **Startup**: Database initialize â†’ Crawler starts â†’ API ready
2. **Background**: Crawler Ù‡Ø± 1 Ø³Ø§Ø¹Øª ØªÙ…Ø§Ù… FindAPhD Ø±Ùˆ crawl Ù…ÛŒâ€ŒÚ©Ù†Ù‡
3. **User Request**: Ø§Ø² database Ù…ÛŒâ€ŒØ®ÙˆÙ†Ù‡ (Ø®ÛŒÙ„ÛŒ Ø³Ø±ÛŒØ¹)
4. **Data Update**: Ù‡Ø± 1 Ø³Ø§Ø¹Øª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ refresh Ù…ÛŒØ´Ù†

---

## ğŸ—ï¸ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡

```
get-phd/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ database/                    # Database Layer
â”‚   â”‚   â”œâ”€â”€ connection.js            # Singleton connection
â”‚   â”‚   â”œâ”€â”€ schema.sql               # Database schema
â”‚   â”‚   â””â”€â”€ repositories/            # Repository Pattern
â”‚   â”‚       â”œâ”€â”€ PhDRepository.js
â”‚   â”‚       â””â”€â”€ CrawlerLogRepository.js
â”‚   â”‚
â”‚   â”œâ”€â”€ crawler/                     # Background Crawler
â”‚   â”‚   â”œâ”€â”€ BackgroundCrawler.js     # Main crawler service
â”‚   â”‚   â”œâ”€â”€ CrawlerScheduler.js      # Scheduler (cron)
â”‚   â”‚   â””â”€â”€ CrawlerObserver.js       # Observer Pattern
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                         # REST API
â”‚   â”‚   â”œâ”€â”€ server-new.js            # Express server v2.0
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ phd.js               # PhD endpoints
â”‚   â”‚       â”œâ”€â”€ crawler.js           # Crawler admin
â”‚   â”‚       â””â”€â”€ health.js            # Health checks
â”‚   â”‚
â”‚   â””â”€â”€ workers/
â”‚       â””â”€â”€ playwrightCrawler.js     # Playwright crawler (reused)
â”‚
â”œâ”€â”€ data/                            # Database files
â”‚   â””â”€â”€ findaphd.db                  # SQLite database
â”‚
â”œâ”€â”€ docs/                            # Ù…Ø³ØªÙ†Ø¯Ø§Øª
â”‚   â””â”€â”€ architecture/
â”‚       â””â”€â”€ NEW-ARCHITECTURE.md      # Ù…Ø¹Ù…Ø§Ø±ÛŒ v2.0
â”‚
â”œâ”€â”€ swagger-v2.json                  # OpenAPI 3.0 spec
â”œâ”€â”€ package.json                     # Dependencies
â””â”€â”€ README-V2.md                     # Ø§ÛŒÙ† ÙØ§ÛŒÙ„
```

---

## ğŸ¨ Design Patterns Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡

### 1. Singleton Pattern
```javascript
// Database & Crawler - ÙÙ‚Ø· ÛŒÚ© instance
Database.getInstance()
BackgroundCrawler.getInstance()
```

### 2. Repository Pattern
```javascript
// Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ business logic Ø§Ø² data access
PhDRepository.search(options)
PhDRepository.findById(id)
```

### 3. Observer Pattern
```javascript
// Monitoring crawler events
BackgroundCrawler.subscribe((event, data) => {
  CrawlerObserver.handleEvent(event, data);
});
```

### 4. Strategy Pattern
```javascript
// Ù…Ø®ØªÙ„Ù crawling strategies
FullCrawlStrategy, IncrementalCrawlStrategy
```

---

## ğŸ”§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª

### Environment Variables
```bash
# Database
DB_TYPE=sqlite                    # sqlite ÛŒØ§ postgresql
SQLITE_PATH=./data/findaphd.db   # Ù…Ø³ÛŒØ± database
DB_HOST=localhost                 # Ø¨Ø±Ø§ÛŒ PostgreSQL
DB_PORT=5432
DB_NAME=findaphd
DB_USER=postgres
DB_PASSWORD=

# Server
PORT=3001
NODE_ENV=development
```

### ØªÙ†Ø¸ÛŒÙ…Ø§Øª Crawler
```bash
# Ø§Ø² Ø·Ø±ÛŒÙ‚ API
curl -X PUT http://localhost:3001/api/crawler/settings/interval \
  -H "Content-Type: application/json" \
  -d '{"hours": 2}'

# ÙØ¹Ø§Ù„/ØºÛŒØ±ÙØ¹Ø§Ù„ Ú©Ø±Ø¯Ù†
curl -X PUT http://localhost:3001/api/crawler/settings/toggle \
  -H "Content-Type: application/json" \
  -d '{"enabled": false}'
```

---

## ğŸ“Š Ø¹Ù…Ù„Ú©Ø±Ø¯

### Benchmarks
| Ù…ØªØ±ÛŒÚ© | v1.0 | v2.0 | Ø¨Ù‡Ø¨ÙˆØ¯ |
|-------|------|------|-------|
| API Response Time | 10-15s | <50ms | **300x faster** |
| FindAPhD Requests | Per user request | Every 1 hour | **99% reduction** |
| Concurrent Users | Limited by browser pool | Unlimited | **Infinite scale** |
| Data Freshness | Real-time | 1 hour | Acceptable trade-off |
| Memory Usage | 256MB | 128MB | 50% less |

### Database Stats
- **ØªØ¹Ø¯Ø§Ø¯ PhD Ù‡Ø§**: 3001+
- **ØªØ¹Ø¯Ø§Ø¯ Ú©Ø´ÙˆØ±Ù‡Ø§**: 50+
- **ØªØ¹Ø¯Ø§Ø¯ Disciplines**: 30+
- **Ø­Ø¬Ù… Ø¯ÛŒØªØ§Ø¨ÛŒØ³**: ~50MB (SQLite)

---

## ğŸ§ª ØªØ³Øª

### 1. ØªØ³Øª Database
```bash
npm run test:db
```

### 2. ØªØ³Øª Crawler
```bash
npm run test:crawler
```

### 3. ØªØ³Øª API
```bash
# Ø´Ø±ÙˆØ¹ Ø³Ø±ÙˆØ±
npm start

# ØªØ³Øª endpoints
curl http://localhost:3001/api/health
curl http://localhost:3001/api/phd/search
curl http://localhost:3001/api/crawler/status
```

---

## ğŸš¢ Deployment

### Production Setup

```bash
# 1. Clone repository
git clone <repo-url>
cd get-phd

# 2. Install dependencies
npm install --production

# 3. ØªÙ†Ø¸ÛŒÙ… environment
export DB_TYPE=postgresql
export DB_HOST=your-db-host
export DB_NAME=findaphd
export DB_USER=postgres
export DB_PASSWORD=your-password
export NODE_ENV=production

# 4. Ø§Ø¬Ø±Ø§ Ø¨Ø§ PM2
npm install -g pm2
pm2 start src/api/server-new.js --name findaphd-api

# 5. Ù…Ø§Ù†ÛŒØªÙˆØ±ÛŒÙ†Ú¯
pm2 logs findaphd-api
pm2 monit
```

### Docker
```dockerfile
FROM node:16
WORKDIR /app
COPY package*.json ./
RUN npm install --production
RUN npx playwright install chromium
COPY . .
EXPOSE 3001
CMD ["npm", "start"]
```

```bash
docker build -t findaphd-api .
docker run -p 3001:3001 -v ./data:/app/data findaphd-api
```

---

## ğŸ”„ Migration Ø§Ø² v1.0 Ø¨Ù‡ v2.0

### ØªØºÛŒÛŒØ±Ø§Øª API

| v1.0 Endpoint | v2.0 Endpoint | ÙˆØ¶Ø¹ÛŒØª |
|---------------|---------------|-------|
| `POST /api/session` | âŒ Removed | Session Ø¯ÛŒÚ¯Ø± Ù„Ø§Ø²Ù… Ù†ÛŒØ³Øª |
| `POST /api/search` | `GET /api/phd/search` | Moved |
| `GET /api/search/:id` | `GET /api/phd/:id` | Moved |
| `POST /api/search/filters/available` | `GET /api/phd/filters/available` | Changed method |

### Breaking Changes
- âŒ Session management Ø­Ø°Ù Ø´Ø¯
- âŒ Real-time crawling Ø­Ø°Ù Ø´Ø¯
- âœ… Ù‡Ù…Ù‡ Ú†ÛŒØ² Ø§Ø² database Ù…ÛŒâ€ŒØ®ÙˆÙ†Ù‡
- âœ… Response format ØªØºÛŒÛŒØ± Ú©Ø±Ø¯Ù‡

### Ù…Ø«Ø§Ù„ Migration
```javascript
// v1.0 âŒ
const session = await createSession();
const results = await search({ sessionId, keywords: 'AI' });

// v2.0 âœ…
const results = await fetch('/api/phd/search?keywords=AI');
// Ø®ÛŒÙ„ÛŒ Ø³Ø§Ø¯Ù‡â€ŒØªØ±! Ø¨Ø¯ÙˆÙ† session
```

---

## ğŸ¯ Roadmap

### âœ… Completed (v2.0)
- [x] Background Crawler Ø¨Ø§ Scheduler
- [x] Database Layer Ø¨Ø§ Repository Pattern
- [x] API Endpoints Ø¬Ø¯ÛŒØ¯
- [x] Monitoring & Logging
- [x] Swagger Documentation

### ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆØ³Ø¹Ù‡
- [ ] Dashboard Ø¨Ø±Ø§ÛŒ Admin
- [ ] WebSocket Ø¨Ø±Ø§ÛŒ real-time updates
- [ ] API Authentication (JWT)
- [ ] Rate Limiting per user

### ğŸ“‹ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡
- [ ] Multi-source crawling (PhD.com, Jobs.ac.uk)
- [ ] ML-based recommendation system
- [ ] Email notifications
- [ ] Advanced analytics
- [ ] GraphQL API

---

## ğŸ“š Ù…Ø³ØªÙ†Ø¯Ø§Øª

- **[NEW-ARCHITECTURE.md](./docs/architecture/NEW-ARCHITECTURE.md)** - Ù…Ø¹Ù…Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ v2.0
- **[Swagger UI](http://localhost:3001/api-docs)** - Ù…Ø³ØªÙ†Ø¯Ø§Øª ØªØ¹Ø§Ù…Ù„ÛŒ API
- **[MIGRATION-GUIDE.md](./docs/MIGRATION-GUIDE.md)** - Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ migrate Ø§Ø² v1

---

## ğŸ¤ Ù…Ø´Ø§Ø±Ú©Øª

```bash
# 1. Fork & Clone
git clone <your-fork>

# 2. Create branch
git checkout -b feature/amazing-feature

# 3. Make changes & test
npm run test:db
npm run test:crawler

# 4. Commit
git commit -m "feat: add amazing feature"

# 5. Push & PR
git push origin feature/amazing-feature
```

---

## ğŸ“„ License

ISC License - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¢Ø²Ø§Ø¯

---

## ğŸ™ Acknowledgments

- **FindAPhD.com** - Ù…Ù†Ø¨Ø¹ Ø¯Ø§Ø¯Ù‡
- **Playwright** - Browser automation
- **Express.js** - Web framework
- **SQLite/PostgreSQL** - Database

---

## ğŸ“ Support

- **Swagger UI**: http://localhost:3001/api-docs
- **GitHub Issues**: Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§Ú¯ Ùˆ feature request
- **Docs**: Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„ Ø¯Ø± Ù¾ÙˆØ´Ù‡ `docs/`

---

**Made with â¤ï¸ for PhD seekers worldwide**

**v2.0.0** - Background Crawler Architecture ğŸš€

